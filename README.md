# ğŸ“Œ AI-Generated Video Detection

### ğŸ” Project Overview

This project tackles the challenge of detecting **AI-generated videos (deepfakes, diffusion-based media)**. With generative models evolving rapidly, detection systems must not only be accurate but also **adapt continually to new forms of synthetic content** without forgetting past knowledge.

My approach leverages **frame-level embeddings** and **transformer-based reasoning (inspired by UNITE)**, extended with **continual learning (UNITE-CL)** to achieve high performance on both old and new data â€” something most continual learning methods struggle with.

---

### âš™ï¸ Key Features

* **Embedding-Powered Pipeline**: Uses SigLIP to create robust frame embeddings.
* **Transformer Backbone (UNITE)**: Learns temporal and spatial relationships across frames for video-level reasoning.
* **Improved Continual Learning (UNITE-CL)**:

  * Unlike typical CL approaches that suffer **accuracy, AUC, and F1 drops**, my model improves performance.
  * Demonstrated **better accuracy on both previously seen datasets and new unseen ones**.
* **Cross-Dataset Generalization**: Trained and tested across diverse benchmarks to avoid dataset bias.
* **Video-Level Prediction**: Outputs a **percentage likelihood** of AI-generated content, not just binary classification.

---

### Architecture Diagram


<img width="1632" height="711" alt="Arch Diagram_final drawio" src="https://github.com/user-attachments/assets/968b201a-5792-4dad-9885-8cd5060e915b" />


### ğŸ—‚ï¸ Repository Structure

```
AI-Generated-Video-Detection/
â”‚â”€â”€ data/          # manifests
â”‚â”€â”€ models/        # UNITE & UNITE-CL implementations
â”‚â”€â”€ train/         # Training scripts
â”‚â”€â”€ eval/          # Evaluation scripts & metrics
â”‚â”€â”€ notebooks/     # Jupyter/Colab notebooks for experimentation
â”‚â”€â”€ results/       # Graphs, metrics, and sample outputs
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

### ğŸ“Š Datasets Used

* **Training / Pretraining**: OpenVid-1M, VidProM samples, Stable Video Diffusion synthetic data.
* **Evaluation / Benchmarks**: FaceForensics++, DFDC (preview + full), Celeb-DF, DeeperForensics, WildDeepfake, UADFV, AEGIS, SHAM, UCF101.
  *(~80GB total, not included in repo â€” links provided separately)*

---

### ğŸš€ Getting Started

1. **Clone the repository**

   ```bash
   git clone https://github.com/<your-username>/AI-Generated-Video-Detection.git
   cd AI-Generated-Video-Detection
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Run demo**

   ```bash
   python demo.py --video sample.mp4
   ```

   Example Output:

   ```
   Prediction: 73% AI-generated
   ```

---

### ğŸ“ˆ Results (To Be Updated)

* âœ… Higher accuracy on both old and new datasets compared to baseline CL methods.
* âœ… Improved AUC and F1-score retention under continual updates.
* âœ… Strong cross-dataset performance showing real-world robustness.
* ğŸ“Š Results and plots (loss curves, ROC, confusion matrices).

---

### ğŸ› ï¸ Future Work

* Add More Synthetic data for the model to train.
* Integrating real-time detection pipelines for streaming platforms.
* Scaling continual learning for unseen generative techniques.
* Exploring lightweight deployment for edge devices.

---

### ğŸ“œ License

MIT License

---

This version tells interviewers at a glance: *â€œThis isnâ€™t just another implementation; it solves a known problem (CL accuracy drop) and beats expectations.â€*

Do you want me to also craft a **short â€œKey Innovationsâ€ block** (like 3 bullets) you could pin at the top of the README for extra emphasis?
